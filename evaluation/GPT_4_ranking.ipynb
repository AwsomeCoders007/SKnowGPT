{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate,  LLMChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "import pandas as pd\n",
    "import re\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpt4_ranking(row):\n",
    "    column_names = row.keys().tolist()\n",
    "    output_column_names = column_names[2:]\n",
    "    \n",
    "    Question=row[\"Question\"]\n",
    "    GT_Answer=row[\"GT_Answer\"]\n",
    "    # SKnowGPT_gpt3=row[\"SKnowGPT_gpt3\"]\n",
    "    # SKnowGPT_mixtral=row[\"SKnowGPT_mixtral\"]\n",
    "    # SKnowGPT_llama3=row[\"SKnowGPT_llama3\"]\n",
    "    # gpt3=row[\"gpt3\"]\n",
    "    # Mixtral=row[\"Mixtral\"]\n",
    "    # Llama3=row[\"Llama3\"]\n",
    "\n",
    "    SKnowGPT_gpt3=row[\"SKnowGPT_gpt3\"]\n",
    "    Mindmap=row[\"Mindmap\"]\n",
    "    gpt3=row[\"gpt3\"]\n",
    "    Only_KG=row[\"Only_KG\"]\n",
    "\n",
    "    \n",
    "    template = \"\"\"\n",
    "    Question: {Question}\n",
    "    \n",
    "    Reference: {GT_Answer}\n",
    "    \n",
    "    Outputs:\n",
    "    Output 1: {SKnowGPT_gpt3}\n",
    "    Output 2: {Mindmap}\n",
    "    Output 3: {gpt3}\n",
    "    Output 4: {Only_KG}\n",
    "    \n",
    "    Task: Rank the outputs based on their factual match to the disease, drug, and test recommendations relevant to the question and provided in the reference answer, from highest to lowest.\n",
    "\n",
    "    Output Format:\n",
    "\n",
    "    1. Output1\n",
    "    2. Output4\n",
    "    3. Output2\n",
    "    4. Output3\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = PromptTemplate(\n",
    "        template = template,\n",
    "        input_variables = output_column_names\n",
    "    )\n",
    "\n",
    "    llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
    "    # llm_response = llm_chain.run(Question=Question,GT_Answer=GT_Answer, SKnowGPT_mixtral=SKnowGPT_mixtral, SKnowGPT_llama3=SKnowGPT_llama3, SKnowGPT_gpt3=SKnowGPT_gpt3, Mixtral=Mixtral, Llama3=Llama3, gpt3=gpt3)\n",
    "    \n",
    "    llm_response = llm_chain.run(Question=Question,GT_Answer=GT_Answer, Mindmap=Mindmap, SKnowGPT_gpt3=SKnowGPT_gpt3, Only_KG=Only_KG, gpt3=gpt3)\n",
    "\n",
    "    return llm_response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_api_key = \"enter_your_openai_api_key\"\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4\",\n",
    "    api_key=openai_api_key,\n",
    "    temperature=0.0,\n",
    "    request_timeout=30,\n",
    "    max_retries=3,\n",
    "    timeout=60 * 3,\n",
    ")\n",
    "\n",
    "# Read the input CSV file \n",
    "# input_file = './GPT4_Ranking_results/GenMedGPT_SKnowGPT_vs_basellms_gpt4_ranking_input.csv'\n",
    "input_file = './GPT4_Ranking_results/GenMedGPT_SKnowGPT_vs_baseline_gpt4_ranking_input.csv'\n",
    "df = pd.read_csv(input_file, encoding='ISO 8859-1')\n",
    "\n",
    "ranking = []\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    print(\"---\",i+1,\"---\")\n",
    "    # gpt4_ranking(row)\n",
    "    llm_response = gpt4_ranking(row)\n",
    "    ranking.append(llm_response)\n",
    "\n",
    "df['GPT_ranking'] = ranking\n",
    "\n",
    "# Write the output to a new CSV file\n",
    "# output_file = './GPT4_Ranking_results/GenMedGPT_SKnowGPT_vs_basellms_gpt4_ranking_output.csv'\n",
    "output_file = './GPT4_Ranking_results/GenMedGPT_SKnowGPT_vs_baseline_table1_gpt4_ranking_output.csv'\n",
    "df.to_csv(output_file, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = './GPT4_Ranking_results/GenMedGPT_SKnowGPT_vs_baseline_table1_gpt4_ranking_output.csv'\n",
    "output_file = './GPT4_Ranking_results/GenMedGPT_SKnowGPT_vs_baseline_table1_gpt4_ranking_output_computed.csv'\n",
    "\n",
    "with open(input_file,'r',newline=\"\") as f_input, open(output_file, 'a+', newline='') as f_output:\n",
    "  reader = csv.reader(f_input)\n",
    "  writer = csv.writer(f_output)\n",
    "\n",
    "  header = next(reader)\n",
    "  # header.extend([\"output1_ranking\",\"output2_ranking\",\"output3_ranking\",\"output4_ranking\",\"output5_ranking\",\"output6_ranking\"])\n",
    "  header.extend([\"output1_ranking\",\"output2_ranking\",\"output3_ranking\",\"output4_ranking\"])\n",
    "  writer.writerow(header)\n",
    "  j = 0\n",
    "  matches = []\n",
    "  for i, row in enumerate(reader):\n",
    "    # print(i)\n",
    "    # print(i, row)\n",
    "    j += 1\n",
    "    # output_text = row[9].lower()\n",
    "    output_text = row[7].lower()\n",
    "    print(output_text)\n",
    "    if len(matches) != 12:\n",
    "      # print(\"1st match \")\n",
    "      matches = re.findall(r'\\d+\\.\\s+(output\\s*\\d+)', output_text)\n",
    "    \n",
    "    rankings = {}\n",
    "    \n",
    "    for i, match in enumerate(matches):\n",
    "      rank = i + 1\n",
    "      output = match.replace(\" \",\"\")\n",
    "      rankings[output] = rank\n",
    "\n",
    "    # print(\"output = \",output)\n",
    "    # print(\"rank = \",rank)\n",
    "\n",
    "    output_dic = {}\n",
    "\n",
    "    for output, rank in sorted(rankings.items(), key=lambda x: x[1]):\n",
    "      output_dic[output]=rank\n",
    "    \n",
    "    # print(\"output_dic: \", output_dic)\n",
    "    try:\n",
    "      # row.extend([output_dic['output1'],output_dic['output2'],output_dic['output3'],output_dic['output4'],output_dic['output5'],output_dic['output6']])\n",
    "      row.extend([output_dic['output1'],output_dic['output2'],output_dic['output3'],output_dic['output4']])\n",
    "      print(\"FINAL ROW = \",row)\n",
    "    except:\n",
    "      # row.extend([0,0,0,0,0,0])\n",
    "      row.extend([0,0,0,0])\n",
    "      continue\n",
    "    writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_column_average(file_path, column_name):\n",
    "    df = pd.read_csv(file_path)\n",
    "    average = df[column_name].mean()\n",
    "    return average\n",
    "\n",
    "# column =[\"output1_ranking\",\"output2_ranking\",\"output3_ranking\",\"output4_ranking\",\"output5_ranking\",\"output6_ranking\"]\n",
    "column =[\"output1_ranking\",\"output2_ranking\",\"output3_ranking\",\"output4_ranking\"]\n",
    "\n",
    "file_path = './GPT4_Ranking_results/GenMedGPT_SKnowGPT_vs_baseline_table1_gpt4_ranking_output_computed.csv'\n",
    "for column_name in column:\n",
    "  average = calculate_column_average(file_path, column_name)\n",
    "  print(f\"The average of column {column_name} is: {round(average, 2)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "umls_ollama3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
